{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hallucination Detection\n",
    "\n",
    "<img src=\"https://live.staticflickr.com/65535/54208132682_73767c3560_b.jpg\" alt=\"Embedded Photo\" width=\"500\">\n",
    "\n",
    "*Image generated using DALL-E model.*\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Language models help us with daily tasks such as correcting texts, writing code, or answering questions. They are also increasingly used in fields like medicine and education.\n",
    "\n",
    "However, how can we know if the answers generated by them are correct? Language models do not always have full knowledge of a given topic, yet they can formulate answers that sound plausible but are actually misleading. Such incorrect answers are called hallucinations.\n",
    "\n",
    "## Task\n",
    "\n",
    "In this task, you will be working on detecting hallucinations in answers to factual questions generated by large language models (LLM).\n",
    "You will analyze a dataset that will help you evaluate whether the answers generated by the language model are actually correct, or contain hallucinations.\n",
    "\n",
    "Each example in the dataset contains:\n",
    "\n",
    "- **Question** e.g. \"What is the main responsibility of the US Department of Defense?\"\n",
    "- **Answer** e.g. \"The main responsibility is national defense..\"\n",
    "- **Tokens** associated with answer generation.\n",
    "- **Four alternative answers** generated by the same model with higher temperature.\n",
    "- **Four alternative tokens** generated by the same model with higher temperature.\n",
    "- **Four alternative probabilities** generated by the same model with higher temperature.\n",
    "- **Etykietę (`is_correct`)** indicating whether the main answer is correct according to a trusted source. \n",
    "\n",
    "Example:\n",
    "```json\n",
    "[\n",
    "    {\n",
    "        \"question_id\": 34,\n",
    "        \"question\": \"What is the name of the low-cost carrier that operates as a wholly owned subsidiary of Singapore Airlines?\",\n",
    "        \"answer\": \"Scoot is the low-cost carrier that operates as a wholly owned subsidiary of Singapore Airlines.\",\n",
    "        \"tokens\": [\" Sco\", \"ot\", \" is\", ..., \" Airlines\", \".\", \"\\n\"],\n",
    "        \"supporting_answers\": [\n",
    "            \"As a wholly owned subsidiary of Singapore Airlines, <answer> Scoot </answer> stands as a low-cost carrier that revolutionized air travel in the region.\",\n",
    "            \"Scoot, a subsidiary of <answer> Singapore Airlines </answer> , is the low-cost carrier that operates under the same brand.\",\n",
    "            \"<answer> Scoot </answer> is the low-cost carrier that operates as a wholly owned subsidiary of Singapore Airlines.\",\n",
    "            \"Singapore Airlines operates a low-cost subsidiary named <answer> Scoot </answer> , offering affordable and efficient air travel options to passengers.\"\n",
    "        ],\n",
    "        \"supporting_tokens\": [\n",
    "            [\" As\", \" a\", ..., \".\", \"<answer>\"],\n",
    "            [\" Sco\", \"ot\", ..., \" brand\", \".\", \"\\n\"],\n",
    "            [\"<answer>\", \" Sco\", ..., \".\", \"\\n\"],\n",
    "            [\" Singapore\", \" Airlines\", ..., \".\", \"\\n\"]\n",
    "        ],\n",
    "        \"supporting_probabilities\": [\n",
    "            [0.0029233775567263365, 0.8621460795402527, ..., 0.018515007570385933],\n",
    "            [0.42073577642440796, 0.9999748468399048, ..., 0.9166142344474792],\n",
    "            [0.3258324861526489, 0.9969879984855652, ..., 0.921079695224762],\n",
    "            [0.11142394691705704, 0.960810661315918, ..., 0.9557166695594788]\n",
    "        ],\n",
    "        \"is_correct\": true\n",
    "    },\n",
    "    .\n",
    "    .\n",
    "    .\n",
    "]\n",
    "```\n",
    "\n",
    "### Data\n",
    "Data available to you in this task:\n",
    "\n",
    "* `train.json` - a dataset containing 2967 questions and answers.\n",
    "* `valid.json` - 990 additional questions.\n",
    "\n",
    "\n",
    "### Evaluation Criteria\n",
    "\n",
    "ROC AUC (ang. *Receiver Operating Characteristic Area Under Curve*) is a measure of the quality of a binary classifier. It shows the model's ability to distinguish between two classes - here, hallucination (false) and correct answer (true). \n",
    "\n",
    "- **ROC (Receiver Operating Characteristic)**: A plot showing the dependency between *True Positive Rate* (sensitivity) and *False Positive Rate* (1-specificity) at different decision thresholds.\n",
    "- **AUC (Area Under Curve)**: The area under the ROC curve, which takes values from 0 to 1:\n",
    "  - **1.0**: Perfect classifier.\n",
    "  - **0.5**: Random classifier (lack of ability to distinguish classes).\n",
    "\n",
    "The higher the AUC value, the better the model performs in classification.\n",
    "\n",
    "You can earn between 0 and 100 points for this task. The result will be linearly scaled based on the ROC AUC value:\n",
    "\n",
    "- **ROC AUC ≤ 0.7**: 0 points.\n",
    "- **ROC AUC ≥ 0.82**: 100 points.\n",
    "- **Values between 0.7 and 0.82**: linearly scaled.\n",
    "\n",
    "The formula for the result:  \n",
    "$$\n",
    "\\text{Punkty} = \n",
    "\\begin{cases} \n",
    "0 & \\text{dla } \\text{ROC AUC} \\leq 0.7 \\\\\n",
    "100 \\times \\frac{\\text{ROC AUC} - 0.7}{0.82 - 0.7} & \\text{dla } 0.7 < \\text{ROC AUC} < 0.82 \\\\\n",
    "100 & \\text{dla } \\text{ROC AUC} \\geq 0.82\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "\n",
    "## Limitations\n",
    "* Your solution will be tested on the Platform without internet access and without GPU.\n",
    "* Evaluation of your final solution on the Platform cannot take longer than 5 minutes without GPU.\n",
    "* List of allowed libraries: `xgboost`, `scikit-learn`, `numpy`, `pandas`, `matplotlib`.\n",
    "\n",
    "\n",
    "## Submission Files\n",
    "This notebook should be completed with your solution (see function `predict_hallucinations`).\n",
    "\n",
    "## Evaluation\n",
    "Remember that during evaluation, the flag `FINAL_EVALUATION_MODE` will be set to `True`.\n",
    "\n",
    "You can earn between 0 and 100 points for this task. The number of points you earn will be calculated based on the ROC AUC value on a secret test set on the Platform, rounded to the nearest integer. If your solution does not meet the above criteria or does not run correctly, you will receive 0 points for the task.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kod Startowy\n",
    "W tej sekcji inicjalizujemy środowisko poprzez zaimportowanie potrzebnych bibliotek i funkcji. Przygotowany kod ułatwi Tobie efektywne operowanie na danych i budowanie właściwego rozwiązania."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### NIE ZMIENIAJ TEJ KOMÓRKI PODCZAS WYSYŁANIA ##########################\n",
    "\n",
    "FINAL_EVALUATION_MODE = False  # W czasie sprawdzania twojego rozwiązania, zmienimy tą wartość na True\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import xgboost as xgb\n",
    "import shutil\n",
    "\n",
    "def download_data(train=(\"1TGEDaxw4GKfSq0fpqSk0wRpUSc8GgZN0\", \"train.json\"),\n",
    "                  valid=(\"1qrr7bZk6Uct8DeC-V8Bc1qD5su56ryFd\", \"valid.json\")):\n",
    "    \"\"\"Pobiera zbiór danych z Google Drive i zapisuje go w folderze 'data'.\"\"\"\n",
    "    import gdown\n",
    "    \n",
    "    # Utwórz lub zresetuj folder 'data'\n",
    "    if not os.path.exists('data'):\n",
    "        os.makedirs('data')\n",
    "    else:\n",
    "        shutil.rmtree('data')\n",
    "        os.makedirs('data')\n",
    "\n",
    "    GDRIVE_DATA = [train, valid]\n",
    "    \n",
    "    for file_id, file_name in GDRIVE_DATA:        \n",
    "        # Pobierz plik z Google Drive i zapisz go w folderze 'data'\n",
    "        url = f'https://drive.google.com/uc?id={file_id}'\n",
    "        output = f'data/{file_name}'\n",
    "        gdown.download(url, output, quiet=False)\n",
    "        \n",
    "        print(f\"Downloaded: {file_name}\")\n",
    "\n",
    "# Pobierz dane tylko jeśli nie jesteś w trybie FINAL_EVALUATION_MODE\n",
    "if not FINAL_EVALUATION_MODE:\n",
    "    download_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ładowanie Danych\n",
    "Za pomocą poniższego kodu dane zostaną wczytane i odpowiednio przygotowane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### NIE ZMIENIAJ TEJ KOMÓRKI PODCZAS WYSYŁANIA ##########################\n",
    "\n",
    "def load_data(folder='data'):\n",
    "    # Wczytaj dane z plików\n",
    "    train_path = os.path.join(folder, 'train.json')\n",
    "    valid_path = os.path.join(folder, 'valid.json')\n",
    "    \n",
    "    with open(train_path, 'r') as f:\n",
    "        train = json.load(f)\n",
    "    with open(valid_path, 'r') as f:\n",
    "        valid = json.load(f)\n",
    "\n",
    "    return train, valid\n",
    "\n",
    "train, valid = load_data(\"data\")\n",
    "\n",
    "print(json.dumps(train[0], indent=2))\n",
    "\n",
    "print(f\"\\nWszystkie przykłady treningowe: {len(train)}\")\n",
    "print(f\"Wszystkie przykłady walidacyjne: {len(valid)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kod z Kryterium Oceniającym\n",
    "\n",
    "Kod, zbliżony do poniższego, będzie używany do oceny rozwiązania na zbiorze testowym."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### NIE ZMIENIAJ TEJ KOMÓRKI PODCZAS WYSYŁANIA ##########################\n",
    "\n",
    "def compute_score(roc_auc: float) -> float:\n",
    "    \"\"\"\n",
    "    Oblicza wynik punktowy na podstawie wartości ROC AUC.\n",
    "\n",
    "    :param roc_auc: Wartość float w zakresie [0.0, 1.0]\n",
    "    :return: Wynik punktowy zgodny z określoną funkcją\n",
    "    \"\"\"\n",
    "    if roc_auc <= 0.7:\n",
    "        return 0\n",
    "    elif 0.7 < roc_auc < 0.82:\n",
    "        return int(round(100 * (roc_auc - 0.7) / (0.82 - 0.7)))\n",
    "    else:\n",
    "        return 100\n",
    "\n",
    "\n",
    "def evaluate_algorithm(dataset, algorithm, verbose=False):\n",
    "    \"\"\"\n",
    "    Ewaluacja algorytmu wykrywania halucynacji na podanym zbiorze danych.\n",
    "\n",
    "    Parametry\n",
    "    ----------\n",
    "    dataset : list\n",
    "        Oznaczony zbiór danych, gdzie każdy element to słownik zawierający klucz 'is_correct'.\n",
    "    algorithm : callable\n",
    "        Funkcja, która przyjmuje pojedynczy przykład (słownik) i zwraca prawdopodobieństwo halucynacji.\n",
    "    verbose : bool\n",
    "        Jeśli True, wypisuje dodatkowe informacje dla każdego przykładu oraz podsumowanie.\n",
    "\n",
    "    Zwraca\n",
    "    -------\n",
    "    roc_auc : float\n",
    "        Wartość pola pod krzywą ROC (ROC AUC) dla predykcji.\n",
    "    \"\"\"\n",
    "    predicted_ys = [] # Lista przechowująca przewidywane prawdopodobieństwa halucynacji\n",
    "\n",
    "    for i, entry in enumerate(dataset):\n",
    "        # Tworzenie kopii próbki i usunięcie etykiety, aby uzyskać dane wejściowe bez oznaczeń\n",
    "        sample_unlabeled = dict(entry)\n",
    "        sample_unlabeled.pop('is_correct', None)\n",
    "\n",
    "        try:\n",
    "            # Przewidywanie prawdopodobieństwa dla pojedynczej próbki\n",
    "            pred_prob = algorithm(sample_unlabeled)\n",
    "            predicted_ys.append(pred_prob)\n",
    "\n",
    "        except Exception as e:\n",
    "            # Jeśli wystąpi błąd, domyślnie ustawiamy prawdopodobieństwo na 0.5\n",
    "            predicted_ys.append(0.5)\n",
    "            if verbose:\n",
    "                print(f\"Sample {i} => Error: {e}\")\n",
    "\n",
    "    predicted_ys = np.array(predicted_ys, dtype=np.float32)\n",
    "    ys = []\n",
    "    for entry in dataset:\n",
    "        ys.append(1 if entry.get('is_correct') else 0)\n",
    "    ys = np.array(ys, dtype=np.int32)\n",
    "    \n",
    "    # Obliczenie metryki ROC AUC\n",
    "    roc_auc = roc_auc_score(ys, predicted_ys)\n",
    "\n",
    "    # Obliczenie końcowego wyniku na podstawie ROC AUC\n",
    "    points = compute_score(roc_auc)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"\\nLiczba próbek: {len(dataset)}\")\n",
    "        print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "        print(f\"Wynik punktowy: {points}\")\n",
    "\n",
    "    return points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twoje Rozwiązanie\n",
    "W tej sekcji należy umieścić Twoje rozwiązanie. Wprowadzaj zmiany wyłącznie tutaj!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Użyj danych treningowych, aby stworzyć tutaj model lub algorytm.\n",
    "\n",
    "def predict_hallucinations(sample):\n",
    "    # TODO: Uruchom swój model lub algorytm na tym zestawie danych.\n",
    "    # TODO: Zwróć listę prawdopodobieństw dla każdego przykładu w zestawie danych.\n",
    "    \n",
    "    prediction = 0.5\n",
    "    return prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ewaluacja\n",
    "\n",
    "Uruchomienie poniższej komórki pozwoli sprawdzić, ile punktów zdobyłoby Twoje rozwiązanie na danych walidacyjnych. Przed wysłaniem upewnij się, że cały notebook wykonuje się od początku do końca bez błędów i bez konieczności ingerencji użytkownika po wybraniu opcji \"Run All\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not FINAL_EVALUATION_MODE:\n",
    "    roc_auc = evaluate_algorithm(valid, predict_hallucinations, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podczas sprawdzania model zostanie zapisany jako `your_model.pkl` i oceniony na zbiorze testowym."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### NIE ZMIENIAJ TEJ KOMÓRKI PODCZAS WYSYŁANIA ##########################\n",
    "if FINAL_EVALUATION_MODE:      \n",
    "    import cloudpickle\n",
    "      \n",
    "    OUTPUT_PATH = \"file_output\"\n",
    "    FUNCTION_FILENAME = \"your_model.pkl\"\n",
    "    FUNCTION_OUTPUT_PATH = os.path.join(OUTPUT_PATH, FUNCTION_FILENAME)\n",
    "\n",
    "    if not os.path.exists(OUTPUT_PATH):\n",
    "        os.makedirs(OUTPUT_PATH)\n",
    "\n",
    "    with open(FUNCTION_OUTPUT_PATH, \"wb\") as f:\n",
    "        cloudpickle.dump(predict_hallucinations, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
