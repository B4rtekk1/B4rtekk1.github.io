{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "V_TqzUruQJrP"
            },
            "source": [
                "# Noise in Data Labels\n",
                "\n",
                "![label_noise_intro.png](https://live.staticflickr.com/65535/54328952408_f7e5bcb7c9_z.jpg)\n",
                "\n",
                "*Image generated using a generative model from OpenArt.ai.*"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "bbULc5cmrh-R"
            },
            "source": [
                "## Introduction"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "mXap1DBercbC"
            },
            "source": [
                "Data is key in machine learning. Everything starts with it. In practice, however, data is often not perfect and contains some noise that reduces its quality. One type of such noise is noise in data labels, which means that for some observations the labels are incorrect.\n",
                "\n",
                "The causes of label noise can be varied. They often result from subjectivity of assessment – different experts may have different opinions, e.g., assessing emotions in photos or the quality of an essay. Another source of error may be annotator fatigue, which affects their concentration and accuracy.\n",
                "\n",
                "Ambiguities can also result from poor data quality, which makes unambiguous classification difficult (e.g., a blurry photo of a dog that resembles a wolf). Sometimes labels are generated automatically by artificial intelligence models, which can also make mistakes.\n",
                "\n",
                "It is worth mentioning samples located on the class boundary. Such cases, e.g., in medical data where symptoms are similar for different diseases, also lead to difficulties in assigning an unambiguous label.\n",
                "\n",
                "Data noise makes it difficult to train a high-quality model because the model may focus more on incorrect information than on general rules contained in it."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "RVGwSAIprjLb"
            },
            "source": [
                "## Task\n",
                "\n",
                "Your task will be to train **two** neural networks for correct binary classification of images despite partial label noise in the training data. The training set is imbalanced (take this into account in your solution). The validation and test set (which will be used to evaluate your final solution) have only correct labels (no noise).\n",
                "\n",
                "**The architecture of the models is defined and you cannot change it.**\n",
                "\n",
                "Think about why we use two models and not one (this is a kind of puzzle) - it will help you understand the task and solve it.\n",
                "Your role in this task is to implement the function `your_select_indices(targets, losses)`, which will select the data indices from the training set that will be used to train the models. The function takes as input a tensor with data labels (`targets`) and a tensor with loss function values from both models (`losses`). The result of this function should be a two-element list where the elements will be tensors containing the indices selected for training the models. One model receives one set of indices, the second model receives the other.\n",
                "Below in the notebook you will find a cell with space for your function. The cell you should modify is clearly marked. To better understand its operation and purpose, it is worth looking at the context and the place where this function will be called in the training loop.\n",
                "\n",
                "### Evaluation Criteria\n",
                "The final evaluation of the task will be based on the average value of the balanced accuracy measure (*BAC*) from two models, i.e., ${BAC}_{mean} = \\frac{BAC_1+BAC_2}{2}$ where $BAC_i$ is the *balanced accuracy* for model $i$, ($i = 1, 2$).\n",
                "\n",
                "For this task, you can score between 0 and 100 points.\n",
                "\n",
                "Your final point score for solving the task will be calculated according to the function below (the higher the value the better) with additional rounding to integer values:\n",
                "$$\n",
                "\\mathrm{Points} =\n",
                "\\begin{cases}\n",
                "    0 & \\text{if } {BAC}_{mean} \\leq 0.5 \\\\\n",
                "    100 \\times \\frac{{BAC}_{mean} - 0.5}{0.8 - 0.5} & \\text{if } 0.5 < {BAC}_{mean} < 0.8 \\\\\n",
                "    100 & \\text{if } {BAC}_{mean} \\geq 0.8\n",
                "\\end{cases}\n",
                "$$\n",
                "\n",
                "**Note: Notice that to get the maximum number of points, it is not necessary to achieve a maximum *balanced accuracy* value equal to 1. If ${BAC}_{mean}$ is at least 0.8, you will receive the maximum number of points.**\n",
                "\n",
                "This criterion and all the functions mentioned above are implemented below by us."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "Pah3rtnOrr7h"
            },
            "source": [
                "## Constraints\n",
                "\n",
                "- Your solution will be tested on the Competition Platform without internet access and in an environment with GPU.\n",
                "- Evaluation of your final solution on the Competition Platform cannot take longer than 5 minutes with a GPU.\n",
                "- **You cannot** change the architecture of the models - it must be the `SmallMobileNet` defined by us."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "8f0E2NDlrwhF"
            },
            "source": [
                "## Submission Files\n",
                "This notebook supplemented with your solution (see `your_select_indices` function)."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "NYF5fUxJr1BX"
            },
            "source": [
                "## Evaluation\n",
                "Remember that during checking, the `FINAL_EVALUATION_MODE` flag will be set to `True`.\n",
                "\n",
                "For this task, you can score between 0 and 100 points. The number of points you will get will be calculated on the (secret) test set on the Competition Platform based on the formula mentioned above, rounded to an integer. If your solution does not meet the above criteria or does not execute correctly, you will receive 0 points for the task."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "starter-header"
            },
            "source": [
                "# Environment Setup\n",
                "\n",
                "First, we define the evaluation mode and import the necessary libraries for deep learning, data manipulation, and visualization."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "mDrJx8xMsCOe"
            },
            "outputs": [],
            "source": [
                "# During the verification of your solution, the value of the FINAL_EVALUATION_MODE flag will be changed to True\n",
                "FINAL_EVALUATION_MODE = False"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "imports-desc"
            },
            "source": [
                "### Library Imports\n",
                "\n",
                "Standard PyTorch components along with Scikit-Learn metrics and PIL for image processing."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "1vTKKO7dsEaN"
            },
            "outputs": [],
            "source": [
                "######################### DO NOT CHANGE THIS CELL ##########################\n",
                "import os\n",
                "from tqdm import tqdm\n",
                "from typing import Optional, Tuple, List\n",
                "\n",
                "import zipfile\n",
                "\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "from PIL import Image\n",
                "\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "from torch.optim import AdamW\n",
                "from torch.utils.data import DataLoader\n",
                "\n",
                "import torchvision.transforms as transforms\n",
                "from torchvision.datasets.folder import VisionDataset\n",
                "\n",
                "from sklearn.metrics import balanced_accuracy_score"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "KL_LMSNKA0CT"
            },
            "source": [
                "## Data Constants\n",
                "\n",
                "Definition of directory paths and source URLs for the training and validation datasets."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "stkLXG_NAPgc"
            },
            "outputs": [],
            "source": [
                "######################### DO NOT CHANGE THIS CELL ##########################\n",
                "SEED = 123\n",
                "IMAGES_DIR = \"data\"\n",
                "TASK_DATASET_LABELS_FILE = \"dataset_labels.csv\"\n",
                "\n",
                "ROOT_DIR = os.getcwd()\n",
                "TRAIN_DATASET_PATH = os.path.join(ROOT_DIR,'train')\n",
                "VAL_DATASET_PATH = os.path.join(ROOT_DIR, 'val')\n",
                "\n",
                "TRAIN_DATASET_URL = \"1qmNNmDv-wUcAv5mvO6vYJV3mQ2SNIGnI\"\n",
                "VAL_DATASET_URL = \"1YUJYD12NmKRSzFJGMrX-a61d6mnTaWbG\""
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "hyperparams-desc"
            },
            "source": [
                "### Training Hyperparameters\n",
                "\n",
                "Setting the computation device (GPU/CPU) and training parameters like learning rate and batch size."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "_BBm56joD-Si"
            },
            "outputs": [],
            "source": [
                "######################### DO NOT CHANGE THIS CELL ##########################\n",
                "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                "LEARNING_RATE = 1e-2\n",
                "NUM_EPOCHS = 6\n",
                "NUM_CLASSES = 2\n",
                "BATCH_SIZE = 128\n",
                "WEIGHT_DECAY = 1e-3\n",
                "\n",
                "if not FINAL_EVALUATION_MODE:\n",
                "  print(f\"Using {DEVICE} device\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "reproducibility-desc"
            },
            "source": [
                "### Reproducibility Setup\n",
                "\n",
                "Function to ensure deterministic behavior across different runs by fixing seeds."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "MuAhda77vDuI"
            },
            "outputs": [],
            "source": [
                "######################### DO NOT CHANGE THIS CELL ##########################\n",
                "def seed_everything(seed: int) -> None:\n",
                "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
                "    np.random.seed(seed)\n",
                "    torch.manual_seed(seed)\n",
                "    torch.backends.cudnn.deterministic = True\n",
                "    torch.backends.cudnn.benchmark = False"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "_8ONQLgUA2vj"
            },
            "source": [
                "## Data Pipeline\n",
                "\n",
                "Logic for downloading and preparing the raw images for the training loop."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "VudHqvfDHtka"
            },
            "outputs": [],
            "source": [
                "######################### DO NOT CHANGE THIS CELL ##########################\n",
                "def download_data(dataset_path, dataset_url):\n",
                "    import gdown\n",
                "    import shutil\n",
                "    output = dataset_path+\".zip\"\n",
                "    if os.path.exists(dataset_path):\n",
                "        shutil.rmtree(dataset_path)\n",
                "    if os.path.exists(output):\n",
                "        os.remove(output)\n",
                "    url = f'https://drive.google.com/uc?id={dataset_url}'\n",
                "    gdown.download(url, output, fuzzy=True)\n",
                "    print(f\"Downloaded: {output}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "dataset-class-desc"
            },
            "source": [
                "### Custom Dataset Implementation\n",
                "\n",
                "The `TaskDataset` class handles loading images and their associated (noisy) labels from a CSV file."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "O263pNeBAbCF"
            },
            "outputs": [],
            "source": [
                "######################### DO NOT CHANGE THIS CELL ##########################\n",
                "class TaskDataset(VisionDataset):\n",
                "    def __init__(self, root: str, transform: Optional[callable] = None):\n",
                "        super().__init__(root, transform=transform)\n",
                "        self.root = root\n",
                "        self.labels_df = pd.read_csv(os.path.join(self.root, TASK_DATASET_LABELS_FILE))\n",
                "\n",
                "    def __len__(self) -> int:\n",
                "        return len(self.labels_df)\n",
                "\n",
                "    def __getitem__(self, idx: int) -> Tuple[Image.Image, np.ndarray]:\n",
                "        img_path = os.path.join(self.root, IMAGES_DIR, self.labels_df.iloc[idx]['file_name'])\n",
                "        img = Image.open(img_path)\n",
                "        label = self.labels_df.iloc[idx]['label']\n",
                "        if self.transform is not None:\n",
                "            img = self.transform(img)\n",
                "        return img, np.array([int(label)])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "unpack-desc"
            },
            "source": [
                "### Data Extraction\n",
                "\n",
                "Utility function to unzip downloaded archives into the local file system."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "UsoOe-u1wANO"
            },
            "outputs": [],
            "source": [
                "######################### DO NOT CHANGE THIS CELL ##########################\n",
                "def unpack_data(unpack_path, dataset_name) -> None:\n",
                "    dataset_zip_path = os.path.join(ROOT_DIR, dataset_name+\".zip\")\n",
                "    if not os.path.exists(os.path.join(unpack_path, dataset_name)):\n",
                "        with zipfile.ZipFile(dataset_zip_path, \"r\") as zip_ref:\n",
                "            zip_ref.extractall(unpack_path)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "dataloader-desc"
            },
            "source": [
                "### Loader Initialization\n",
                "\n",
                "Wraps datasets into DataLoaders for efficient batch processing."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "HTkEhPtYA799"
            },
            "outputs": [],
            "source": [
                "######################### DO NOT CHANGE THIS CELL ##########################\n",
                "def load_data() -> Tuple[DataLoader, DataLoader]:\n",
                "    base_transform = transforms.Compose([transforms.ToTensor()])\n",
                "    train_dataset = TaskDataset(root=TRAIN_DATASET_PATH, transform=base_transform)\n",
                "    val_dataset = TaskDataset(root=VAL_DATASET_PATH, transform=base_transform)\n",
                "    train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
                "    val_loader = DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
                "    return train_loader, val_loader"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "data-prep-execution"
            },
            "source": [
                "### Dataset Preparation Execution\n",
                "\n",
                "Running the download, unpacking, and loading steps sequentially."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "vqHpbHVfhb5N"
            },
            "outputs": [],
            "source": [
                "######################### DO NOT CHANGE THIS CELL ##########################\n",
                "if not FINAL_EVALUATION_MODE:\n",
                "    download_data(TRAIN_DATASET_PATH, TRAIN_DATASET_URL)\n",
                "    download_data(VAL_DATASET_PATH, VAL_DATASET_URL)\n",
                "    unpack_data(ROOT_DIR, \"train\")\n",
                "    unpack_data(ROOT_DIR, \"val\")\n",
                "    train_loader, val_loader = load_data()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "GDTOKmvwB4Ai"
            },
            "source": [
                "## Model Architecture\n",
                "\n",
                "Crucially, we use the `SmallMobileNet` architecture, which uses depthwise separable convolutions to stay computationally efficient for the 5-minute GPU limit."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "Qkxih_KVAj54"
            },
            "outputs": [],
            "source": [
                "######################### DO NOT CHANGE THIS CELL ##########################\n",
                "class SmallMobileNet(nn.Module):\n",
                "    def __init__(self, num_classes=NUM_CLASSES):\n",
                "        super(SmallMobileNet, self).__init__()\n",
                "        self.features = nn.Sequential(\n",
                "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1, bias=False),\n",
                "            nn.BatchNorm2d(32),\n",
                "            nn.ReLU6(inplace=True),\n",
                "            nn.Conv2d(32, 256, kernel_size=1, stride=1, bias=False), # Simplified view for display\n",
                "            nn.BatchNorm2d(256),\n",
                "            nn.ReLU6(inplace=True),\n",
                "        )\n",
                "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
                "        self.classifier = nn.Sequential(\n",
                "            nn.Linear(256, 128),\n",
                "            nn.ReLU6(inplace=True),\n",
                "            nn.Dropout(0.5),\n",
                "            nn.Linear(128, num_classes),\n",
                "        )\n",
                "\n",
                "    def forward(self, x):\n",
                "        x = self.features(x)\n",
                "        x = self.pool(x)\n",
                "        x = torch.flatten(x, 1)\n",
                "        x = self.classifier(x)\n",
                "        return x"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "evaluation-logic-desc"
            },
            "source": [
                "## Evaluation Criteria\n",
                "\n",
                "Functions to calculate Balanced Accuracy (BAC) and translate it into the final competition score."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "4APzhbt9BE3h"
            },
            "outputs": [],
            "source": [
                "######################### DO NOT CHANGE THIS CELL ##########################\n",
                "def predict_and_evaluate(model, val_loader, device, verbose=False):\n",
                "    model.eval()\n",
                "    all_preds, all_targets = [], []\n",
                "    with torch.no_grad():\n",
                "        for inputs, targets in val_loader:\n",
                "            inputs, targets = inputs.to(device), targets.to(device)\n",
                "            outputs = model(inputs)\n",
                "            preds = torch.argmax(outputs, dim=1)\n",
                "            all_preds.extend(preds.cpu().numpy())\n",
                "            all_targets.extend(targets.cpu().numpy())\n",
                "    bac = balanced_accuracy_score(all_targets, all_preds)\n",
                "    if verbose: print(f\"Balanced Accuracy: {bac}\")\n",
                "    return bac"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "performance-desc"
            },
            "source": [
                "### Score Mapping\n",
                "\n",
                "Translates the mean BAC from both models into a 0-100 score."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "jd5RQhtepPQo"
            },
            "outputs": [],
            "source": [
                "######################### DO NOT CHANGE THIS CELL ##########################\n",
                "def performance(bac_1: float, bac_2: float) -> None:\n",
                "    bac_mean = (bac_1 + bac_2) / 2\n",
                "    if bac_mean <= 0.5: points = 0\n",
                "    elif 0.5 < bac_mean < 0.8: points = int(round((bac_mean - 0.5) / 0.3 * 100))\n",
                "    else: points = 100\n",
                "    print(f\"Final Score: {points}/100\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "idShIZwfjzAr"
            },
            "source": [
                "## Training Infrastructure\n",
                "\n",
                "The standard training loop is modified here to accept a `select_indices_fn`. This allows us to dynamically filter out noisy samples during training."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "FpnzpyhnxxVC"
            },
            "outputs": [],
            "source": [
                "######################### DO NOT CHANGE THIS CELL ##########################\n",
                "def train(model1, model2, optimizer1, optimizer2, criterion, train_loader, val_loader, num_epochs, device, select_indices_fn):\n",
                "    for epoch in range(1, num_epochs + 1):\n",
                "        model1.train(); model2.train()\n",
                "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch}\")\n",
                "        for inputs, targets in pbar:\n",
                "            inputs, targets = inputs.to(device), targets.squeeze().long().to(device)\n",
                "            outputs = [m(inputs) for m in (model1, model2)]\n",
                "            losses = [criterion(out, targets) for out in outputs]\n",
                "            \n",
                "            # The selection strategy is applied here\n",
                "            selected_indices = select_indices_fn(targets, losses)\n",
                "            \n",
                "            for i, (model, optim) in enumerate([(model1, optimizer1), (model2, optimizer2)]):\n",
                "                optim.zero_grad()\n",
                "                sel = selected_indices[i]\n",
                "                if len(sel) > 0:\n",
                "                    loss = criterion(model(inputs[sel]), targets[sel]).mean()\n",
                "                    loss.backward(); optim.step()\n",
                "    return {}"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "z7uonc2-mCak"
            },
            "source": [
                "## Example Baseline\n",
                "\n",
                "As a baseline, we use all samples regardless of their loss, which typically leads to overfitting on the noise."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "AOI8Venajwal"
            },
            "outputs": [],
            "source": [
                "######################### DO NOT CHANGE THIS CELL ##########################\n",
                "def default_select_indices(targets, losses):\n",
                "    return [torch.arange(targets.shape[0]).to(DEVICE) for _ in range(2)]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "0GLrTYyoqhJT"
            },
            "source": [
                "# Solved Solution\n",
                "\n",
                "The proposed solution implements a **Co-teaching** framework tailored for **imbalanced datasets**. \n",
                "\n",
                "### Why Co-teaching?\n",
                "Deep neural networks exhibit a \"memorization effect\" — they learn simple, generalizable patterns (clean data) before memorizing noise. By training two models in parallel, each model can identify low-loss samples and \"teach\" them to its peer. This cross-filtering avoids the feedback loop where a single model might justify its own errors.\n",
                "\n",
                "### Handling Imbalance\n",
                "In imbalanced datasets, standard loss filtering would purely favor the majority class because it's easier to minimize. To solve this, we:\n",
                "1.  **Class-Wise Filtering**: We sort losses independently for class 0 and class 1.\n",
                "2.  **Proportional Selection**: We keep a balanced ratio (e.g., 85%) of samples from each class, ensuring the models see enough minority class samples to achieve high Balanced Accuracy."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "mNMjWrAvqldU"
            },
            "outputs": [],
            "source": [
                "def your_select_indices(targets: torch.Tensor, losses: List[torch.Tensor]) -> List[torch.Tensor]:\n",
                "    \"\"\"\n",
                "    Solution using Class-Aware Co-teaching Selection.\n",
                "    \"\"\"\n",
                "    batch_size = targets.shape[0]\n",
                "    device = targets.device\n",
                "    loss1, loss2 = losses\n",
                "    \n",
                "    # Get class masks and indices\n",
                "    indices = torch.arange(batch_size, device=device)\n",
                "    c0_mask, c1_mask = (targets == 0), (targets == 1)\n",
                "    \n",
                "    # Maintain a high keep ratio for imbalanced robustness\n",
                "    keep_ratio = 0.85\n",
                "    c0_keep = int(c0_mask.sum().item() * keep_ratio)\n",
                "    c1_keep = int(c1_mask.sum().item() * keep_ratio)\n",
                "    \n",
                "    def filter_for_peer(peer_loss):\n",
                "        # Sort class 0 samples by peer loss\n",
                "        _, s0 = torch.sort(peer_loss[c0_mask])\n",
                "        sel0 = indices[c0_mask][s0[:c0_keep]]\n",
                "        \n",
                "        # Sort class 1 samples by peer loss\n",
                "        _, s1 = torch.sort(peer_loss[c1_mask])\n",
                "        sel1 = indices[c1_mask][s1[:c1_keep]]\n",
                "        \n",
                "        return torch.cat([sel0, sel1])\n",
                "\n",
                "    # Model 1 trains on low-loss samples from Model 2 (and vice versa)\n",
                "    return [filter_for_peer(loss2), filter_for_peer(loss1)]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "execution-header"
            },
            "source": [
                "## Execution and Results\n",
                "\n",
                "We now run the training process using our custom selection strategy and evaluate the final performance against the competition metric."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "T3Btb8AY0hD0"
            },
            "outputs": [],
            "source": [
                "######################### DO NOT CHANGE THIS CELL ##########################\n",
                "if not FINAL_EVALUATION_MODE:\n",
                "    seed_everything(SEED)\n",
                "    criterion = nn.CrossEntropyLoss(reduction=\"none\")\n",
                "    m1, m2 = SmallMobileNet().to(DEVICE), SmallMobileNet().to(DEVICE)\n",
                "    opt1 = AdamW(m1.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
                "    opt2 = AdamW(m2.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
                "\n",
                "    train(m1, m2, opt1, opt2, criterion, train_loader, val_loader, NUM_EPOCHS, DEVICE, your_select_indices)\n",
                "\n",
                "    b1 = predict_and_evaluate(m1, val_loader, DEVICE, verbose=True)\n",
                "    b2 = predict_and_evaluate(m2, val_loader, DEVICE, verbose=True)\n",
                "    performance(b1, b2)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "wgwPClAjVqPZ"
            },
            "source": [
                "# Official Evaluation\n",
                "\n",
                "The function below is used by the platform to calculate the final score on the hidden test set."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "VCmm0PK2pw14"
            },
            "outputs": [],
            "source": [
                "######################### DO NOT CHANGE THIS CELL ##########################\n",
                "def final_evaluate(evaluate_data_path, model1, model2):\n",
                "    base_transform = transforms.Compose([transforms.ToTensor()])\n",
                "    loader = DataLoader(TaskDataset(evaluate_data_path, transform=base_transform), batch_size=BATCH_SIZE)\n",
                "    b1 = predict_and_evaluate(model1, loader, DEVICE, verbose=True)\n",
                "    b2 = predict_and_evaluate(model2, loader, DEVICE, verbose=True)\n",
                "    return performance(b1, b2)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}